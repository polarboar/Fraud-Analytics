{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = pd.read_csv('data.csv')\n",
    "original_dataset = original_dataset\n",
    "original_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop transactions with value 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = original_dataset\n",
    "dataset = dataset.drop(dataset[dataset['Amt'] == 0].index)\n",
    "dataset = dataset.drop(dataset[dataset['Buyer'] == dataset['Seller']].index)\n",
    "#dataset = dataset[:200000]\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing benford analysis on the overall transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10\n",
    "\n",
    "def benford_analysis(vals):\n",
    "    # Expected Benford frequencies\n",
    "    expected_freq = [round(len(vals) * log10(1 + 1/d)) for d in range(1, 10)]\n",
    "\n",
    "    # Convert to scientific notation and get first digit\n",
    "    first_digit = lambda x: int(('%e' % x)[0])\n",
    "\n",
    "    # Get observed first digit frequencies\n",
    "    observed_freq = [0] * 10\n",
    "    for val in vals:\n",
    "        observed_freq[first_digit(val)] += 1\n",
    "    observed_freq = observed_freq[1:]\n",
    "\n",
    "    print('Expected frequencies: ', expected_freq)\n",
    "    print('Observed frequencies: ', observed_freq)\n",
    "    \n",
    "    plt.plot(range(1, 10), expected_freq, label='Expected')\n",
    "    plt.plot(range(1, 10), observed_freq, label='Observed')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    mean_abs_dev = 1/(len(vals)*9) * sum([abs(obv-exp)\n",
    "                                          for obv, exp in zip(observed_freq, expected_freq)])\n",
    "    print('Mean absolute deviation: %.6lf' % mean_abs_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benford_analysis(dataset['Amt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Mean Absolute Deviation (MAD) is around 0.017 which implies a nonconformity between the expected probability and} \\\\ \\text{the observed probability.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning the transaction graph\n",
    "\n",
    "- We only consider the nodes (users) which have both incoming and outgoing edges.\n",
    "- This is because our goal is to identify circular trading and nodes need to have both incoming and outgoing edges to be part of a cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sellers = set(dataset['Seller'])\n",
    "buyers = set(dataset['Buyer'])\n",
    "seller_buyer_union = sellers.union(buyers)\n",
    "seller_buyer_intersection = sellers.intersection(buyers)\n",
    "\n",
    "print('Sellers:', len(sellers))\n",
    "print('Buyers:', len(buyers))\n",
    "print('Sellers Union Buyers:', len(seller_buyer_union))\n",
    "print('Sellers Intersection Buyers:', len(seller_buyer_intersection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "for seller, buyer, amt in dataset[['Seller', 'Buyer', 'Amt']].values:\n",
    "    if (seller in seller_buyer_intersection\n",
    "            and buyer in seller_buyer_intersection):\n",
    "        G.add_weighted_edges_from([(int(seller), int(buyer), amt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To access edges with weights set data=True\n",
    "#G.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Betweenness Clustering\n",
    "\n",
    "from networkx.algorithms.community.centrality import girvan_newman\n",
    "\n",
    "clusters = girvan_newman(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuple(sorted(c) for c in next(clusters))\n",
    "\n",
    "#cluster = tuple(sorted(c) for c in next(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Number of clusters: \", len(cluster))\n",
    "\n",
    "# print(cluster[1])\n",
    "\n",
    "# for i in G.edges:\n",
    "#     if i[0] in cluster[1]  and i[1] in cluster[1]:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HCS\n",
    "\n",
    "#edges = nx.minimum_edge_cut(G)\n",
    "\n",
    "# UG1 = nx.Graph(G)\n",
    "# UG = UG1\n",
    "\n",
    "# print(\"Number of components: \", nx.number_connected_components(UG1))\n",
    "\n",
    "# comp = nx.connected_components(UG1)\n",
    "\n",
    "# cnt = 0\n",
    "\n",
    "# for i in comp:\n",
    "#     UG = UG1.subgraph(i).copy()\n",
    "#     cnt += 1\n",
    "#     if cnt > 0:\n",
    "#         break\n",
    "    \n",
    "# print(\"Len: \", len(UG.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return sets of nodes after running HCS\n",
    "# Graph should be connected at first\n",
    "\n",
    "def HCS(G):\n",
    "    edges = nx.minimum_edge_cut(G)\n",
    "    \n",
    "    #print(\"Big bum\")\n",
    "    \n",
    "    num_nodes = len(G.nodes());\n",
    "    if (num_nodes < 3) or (len(edges) > num_nodes/2) :\n",
    "        #print(\"Nodes: \", G.nodes())\n",
    "        return [list(G.nodes())]\n",
    "    \n",
    "    for i in edges:\n",
    "        #print(i)\n",
    "        G.remove_edge(i[0], i[1])\n",
    "    \n",
    "    num_comps = nx.number_connected_components(G)\n",
    "#     if  num_comps < 2:\n",
    "#         print()\n",
    "#         return [sorted(list(G.nodes()))]\n",
    "    \n",
    "    comp = nx.connected_components(G)\n",
    "    \n",
    "    graphs = []\n",
    "    for i in comp:\n",
    "        g = G.subgraph(i).copy()\n",
    "        graphs += HCS(g)\n",
    "        \n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(HCS(UG.copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights of Triangles\n",
    "\n",
    "def get_weighted_graph(G):\n",
    "    \n",
    "    weights = []\n",
    "    \n",
    "    print(\"Num edges: \", len(G.edges()))\n",
    "    \n",
    "    edge_set = {}\n",
    "    \n",
    "    for i in range(len(G.edges())):\n",
    "        weights.append([0,0,0,0])\n",
    "    \n",
    "    for i, edge in enumerate(G.edges()):\n",
    "        u = edge[0]\n",
    "        v = edge[1]\n",
    "        \n",
    "        suc_set = set(list(G.successors(v)))\n",
    "        pred_set = set(list(G.predecessors(u)))\n",
    "        \n",
    "        common = suc_set.intersection(pred_set)\n",
    "        \n",
    "        for j in common:\n",
    "            cnt = 0\n",
    "            if G.has_edge(v,u):\n",
    "                cnt+=1\n",
    "            if G.has_edge(j,v):\n",
    "                cnt+=1\n",
    "            if G.has_edge(u,j):\n",
    "                cnt+=1\n",
    "                \n",
    "            weights[i][cnt] = cnt+1\n",
    "            \n",
    "            if u < v:\n",
    "                edge_set[(u,v)] = max(edge_set.get((u,v),0),cnt+1)\n",
    "            else :\n",
    "                edge_set[(v,u)] = max(edge_set.get((v,u),0),cnt+1)\n",
    "            \n",
    "            #print(\"u: \", u, \", v: \", v, \", j: \", j)\n",
    "        \n",
    "    ans_graph = nx.Graph()\n",
    "\n",
    "    #for i, edge in enumerate(G.edges()):\n",
    "    #    ans_graph.add_weighted_edges_from([(edge[0], edge[1], max(weights[i]))])\n",
    "    \n",
    "    for (u,v),w in edge_set.items():\n",
    "        ans_graph.add_weighted_edges_from([(u, v, w)]) \n",
    "        \n",
    "    return ans_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp = nx.complete_graph(10)\n",
    "# tmp = nx.DiGraph()\n",
    "# tmp.add_edge(1,2)\n",
    "# tmp.add_edge(2,1)\n",
    "# tmp.add_edge(2,3)\n",
    "# tmp.add_edge(3,1)\n",
    "# tmp.add_edge(1,4)\n",
    "# tmp.add_edge(4,5)\n",
    "# tmp.add_edge(5,1)\n",
    "# tmp.add_edge(5,6)\n",
    "\n",
    "tmp = G\n",
    "\n",
    "tmp = get_weighted_graph(tmp)\n",
    "\n",
    "# #tmp.edges(data=True)\n",
    "print(\"Edges: \", len(tmp.edges()))\n",
    "print(\"Nodes: \", len(tmp.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## kNN filter\n",
    "def get_k_n(G, n, k):\n",
    "    edges = list(G.out_edges(n, data=True))\n",
    "    \n",
    "    edges.sort(key = lambda x : x[-1]['weight'], reverse=True)\n",
    "    \n",
    "    return edges[:k]\n",
    "    #print(edges[0])\n",
    "\n",
    "def knn_filter(G, k):\n",
    "    node_list = list(G.nodes())\n",
    "    \n",
    "    ans_graph = nx.DiGraph()\n",
    "    \n",
    "    for i in node_list:\n",
    "        edges = get_k_n(G, i, k)\n",
    "        ans_graph.add_weighted_edges_from( [(edge[0], edge[1], edge[-1]['weight']) for edge in edges] )\n",
    "        \n",
    "    return ans_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = nx.DiGraph()\n",
    "tmp.add_weighted_edges_from([(1,2,10), (1,3,12), (1,4,10), (2,3,7), (2,4,4), (3,1,6), (3,4,3), (3,5,100)])\n",
    "# tmp.add_edge(2,1, weight=10)\n",
    "# tmp.add_edge(2,3, weight=10)\n",
    "# tmp.add_edge(3,1, weight=10)\n",
    "# tmp.add_edge(1,4, weight=10)\n",
    "# tmp.add_edge(4,5, weight=10)\n",
    "# tmp.add_edge(5,1, weight=10)\n",
    "# tmp.add_edge(5,6, weight=10)\n",
    "\n",
    "tmp = knn_filter(tmp, 2)\n",
    "tmp.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collusion clustering\n",
    "def is_km_compatible(G, p, d_size, m):\n",
    "    if len(G.edges(p)) >= min(m, d_size):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_kmh_compatible(G, s1, s2, m, h):\n",
    "    \n",
    "    s1_percent = 0\n",
    "    for i in s1:\n",
    "        if is_km_compatible(G, i, len(s2), m) :\n",
    "            s1_percent += 1\n",
    "    s1_percent /= len(s1)\n",
    "    \n",
    "    s2_percent = 0\n",
    "    for i in s2:\n",
    "        if is_km_compatible(G, i, len(s1), m) :\n",
    "            s2_percent += 1\n",
    "    s2_percent /= len(s2)\n",
    "    \n",
    "    if s1_percent >= h and s2_percent >= h:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def collusion_index(G, s):\n",
    "    i_c = 0\n",
    "    e_c = 0\n",
    "    \n",
    "    for edge in G.edges(data=True):\n",
    "        if edge[0] in s and edge[1] in s:\n",
    "            i_c += edge[-1]['weight']\n",
    "            continue\n",
    "            \n",
    "        if edge[0] in s or edge[1] in s:\n",
    "            e_c += edge[-1]['weight']\n",
    "            \n",
    "    if e_c == 0:\n",
    "        return 100\n",
    "        \n",
    "    return i_c/e_c\n",
    "\n",
    "def collusion_level(G, s1, s2):\n",
    "    s = s1.intersection(s2)\n",
    "    return collusion_index(G, s)\n",
    "\n",
    "# Make sure 1 <= m <= k\n",
    "def collusion_clustering(G, k, m, h):\n",
    "    \n",
    "    G = knn_filter(G, k)\n",
    "    S = []\n",
    "    for i in G.nodes():\n",
    "        S.append({i})\n",
    "        \n",
    "    #print(S)\n",
    "    \n",
    "    while True:\n",
    "        B = []\n",
    "        for i, s_i in enumerate(S):\n",
    "            for j in range(i+1,len(S)):\n",
    "                s_j = S[j]\n",
    "                B.append((s_i, s_j, collusion_level(G, s_i, s_j)))\n",
    "    \n",
    "        B.sort(key = lambda x : x[-1], reverse=True)\n",
    "        \n",
    "        no_change = True\n",
    "        \n",
    "        for i in B:\n",
    "            if (i[0] not in S) or (i[1] not in S):\n",
    "                continue\n",
    "                \n",
    "            if i[-1] > 0 and is_kmh_compatible(G, i[0], i[1], m, h) :\n",
    "                no_change = False\n",
    "                S.remove(i[0])\n",
    "                S.remove(i[1])\n",
    "                \n",
    "                new_set = i[0].union(i[1])\n",
    "                \n",
    "                S.append(new_set)\n",
    "                \n",
    "        if no_change:\n",
    "            break\n",
    "            \n",
    "    return S\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp = nx.DiGraph()\n",
    "#tmp.add_weighted_edges_from([(1,2,10), (1,3,12), (1,4,10), (2,3,7), (2,4,4), (3,1,6), (3,4,3), (3,5,100)])\n",
    "\n",
    "tmp = get_weighted_graph(G)\n",
    "#sets = collusion_clustering(tmp, 2, 1, 0.5)\n",
    "comp = nx.connected_components(tmp)\n",
    "\n",
    "for i in comp:\n",
    "    tmp = tmp.subgraph(i).copy()\n",
    "    break\n",
    "\n",
    "sets = HCS(tmp)\n",
    "\n",
    "print(\"Len: \", len(sets))\n",
    "print(sets)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
